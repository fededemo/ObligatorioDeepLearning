{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obligatorio de Deep Learning - Semestre 2 - 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63fa02cc6f3a2593013a53dcd20bdd9c54533efb"
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Embedding, LSTM, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### 1.2 Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "np.random.seed(117)\n",
    "tf.random.set_seed(117)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "## 2. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d69ff10797c793abb7c5a05594f8d3463769995"
   },
   "outputs": [],
   "source": [
    "hdfs_train, hdfs_test_kaggle = utils.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d69ff10797c793abb7c5a05594f8d3463769995",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdfs_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_test_kaggle[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1419a5e71da60223177d900fd0e432e46bfa67a0"
   },
   "source": [
    "## 3. Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Análisis descriptivo general: Distribuciones, Scatterplots, Barplots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.value_counts(hdfs_train,'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Análisis de secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregar ploteo de largos de secuencias, distribuciones por simbolo, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sequences, data_y = utils.load_sequences_and_target(hdfs_train, one_hot=True)\n",
    "#raw_sequences, data_y = utils.load_sequences_and_target(hdfs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min([min(s) for s in raw_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([max(s) for s in raw_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(s) for s in raw_sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El valor de vocab_size es importante ya que es la dimensionalidad del lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = max([max(s) for s in raw_sequences]) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definiremos arbitrariamente el largo máximo de secuencias (es este tamaño razonable?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Haremos padding de valor 0 a las secuencias para estandarizar el largo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = utils.pad_sequences(raw_sequences, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79fb4788f90b3603c8b71472f44647b808bab25e"
   },
   "source": [
    "## 4. Entrenamiento de Language Model\n",
    "\n",
    "### 4.1. Data preprocessing\n",
    "#### 4.1.1 Particionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a167115aa4fcc937097a1c5c8899b909f33fb2d5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = utils.split(padded_sequences, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f969b9f496c11dacac4583a319f3dcbd56d3a6ea"
   },
   "source": [
    "### 4.2 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "import math\n",
    "embedding_size = math.ceil(vocab_size**0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, embedding_size, input_length=max_len))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Hiperarámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "053d12032f6d113094617826f5f78bba8555c115"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 1\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "053d12032f6d113094617826f5f78bba8555c115"
   },
   "outputs": [],
   "source": [
    "training1, model1 = utils.train(model,\n",
    "                X_train,\n",
    "                y_train, \n",
    "                batch_size = batch_size,\n",
    "                epochs = epochs,\n",
    "                validation_data_X = X_val, \n",
    "                validation_data_y = y_val,                                \n",
    "                patience = patience,\n",
    "                class_weights = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac639c24adf884c806ce1ab985fe7db7e9aab26a"
   },
   "source": [
    "### 4.4 Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b096e119c62a41dc227ad9f12131ca0c28dbed8b"
   },
   "outputs": [],
   "source": [
    "utils.eval_model(training1, model1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Generación de salida para competencia Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.load_test_sequences_and_generate_prediction_file(model1, hdfs_test_kaggle, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Consigna\n",
    "\n",
    "### A) Participación en Competencia Kaggle:\n",
    "El objetivo de este punto es participar en la competencia de Kaggle y obtener como mínimo un Macro Average Recall (o Weighted Accuracy) superior al 80%. [->Link a la competencia<-](https://www.kaggle.com/t/6d15e3a96bd049b2b4b2a491a69a0fc7).\n",
    "\n",
    "### B) Utilización de Grid Search (o equivalente):\n",
    "Para cumplir con la busqueda de modelos óptimos se debe realizar un grid search lo más abarcativo y metódico posible.\n",
    "\n",
    "### C) Se debe a su vez investigar e implementar al menos 2 de las siguientes técnicas:\n",
    "#### 1. [Batch Normalization](https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/)\n",
    "#### 2. [Data Augmentation a través de la realización de Windowing](https://blog.finxter.com/how-to-loop-through-a-python-list-in-batches/#Method_1_Iterating_over_Consecutive_Sliding_Windows)\n",
    "#### 3. [Gradient Normalization y/o Gradient Clipping](https://machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c12d86b63e74ac4f427027e3d58b1fa461278ba669d7be39fd5f25ce787fdf43"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
